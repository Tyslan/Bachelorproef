\chapter{Data importeren in Cassandra}
\label{ch:cassandra_import}

\section{Importeren via cqlsh}
Om de data via cqlsh te kunnen importeren dient eerst een keyspace aangemaakt te worden.
Bij het aanmaken van deze keyspace dient de replicatie strategie en de replicatie factor meegegeven te worden.
Na het aanmaken van de keyspace, dient men hierin de tabel waarin de data geïmporteerd zal worden, aan te maken.

Nu kunnen we door middel van het 'COPY' commando, dat binnen cql aangeboden wordt data importeren in Cassandra \citep{Cannon2012Import}.
%TODO copy commando invoeren

Een aantal zaken dienen hierbij opgemerkt te worden.

\begin{enumerate}
	\item De volgorde van de kolommen kan gespecificeerd worden aangezien Cassandra de kolommen automatisch alfabetisch sorteert en dit niet noodzakelijk het geval is bij het csv bestand.
	\item Het scheidingsteken van de velden in het csv bestand kan gespecificeerd worden evenals de encapsulering van de velden.
	\item Er kan specifiek meegegeven worden wat Cassandra moet aanvangen met de null waarde.
\end{enumerate}

Dit is een zeer eenvoudige manier om data te importeren in Cassandra.
Alle inserts gebeuren asynchroon, wat uiteraard goed is.
Toch wordt deze methode niet aangeraden om te gebruiken bij het importeren van grote hoeveelheden data.
Een eerste reden is dat er maar met één node connectie gemaakt wordt.
Hierdoor wordt de werklast niet evenwichtig verdeeld over alle nodes.
Bij ca. 1 miljoen rijen, afhankelijk van het aantal kolommen, kan het zijn dat deze methode vastloopt.

De bovenstaande problemen kan men op een aantal manieren oplossen.
De drie meest voorkomende zijn:

\begin{enumerate}
	\item Het opsplitsen van één groot csv bestand in verschillende kleinere bestanden.
	\item Het gebruik van de sstableloader die Cassandra voorziet.
	\item Het gebruik van cassandra-loader
\end{enumerate}

\section{Importeren met sstableloader}

Het importeren van data met sstableloader is eveneens een eenvoudig proces, maar hier komt wat meer werk aan te pas.

Enkele belangrijke nadelen van deze manier van werken zijn:
\begin{itemize}
	\item Men moet een aangepaste applicatie schrijven om dit te kunnen gebruiken.
	\item Om sstableloader te kunnen gebruiken dienen alle nodes van de cluster online te zijn.
	\item De sstable dient aangemaakt te zijn vooraleer men deze methode kan gebruiken.
\end{itemize}

De reden waarom alle nodes online moeten zijn is omdat de hash van het record meteen bepaald en daarna doorgestuurd wordt naar de node waarop de data hoort te staan.

\section{Importeren met cassandra-loader}
%TODO referentie
Dit is een Java programma van Brian Hess.
Dit programma maakt gebruik van de CQL driver, die beschikbaar gesteld wordt door DataStax.
Het ganse principe van dit programma is om asynchroon te werken en om met iedere node in de cluster verbinding te maken.
Op deze manier kan het werk evenwichtig verdeeld worden.
Dit laatste was één van de struikelblokken bij het importeren van data via cqlsh.

\section{Testen van de verschillende loaders}
In dit stuk is het de bedoeling om de verschillende manieren van data import te vergelijken.
In deze vergelijking werd altijd dezelfde data gebruikt.
Enkel het aantal records dat ingeladen werd, was verschillend.

Eerst was de meest eenvoudige manier aan de beurt, het COPY commando via cqlsh.
Hier werden verschillende bestanden met dezelfde data, maar met een ander aantal rijen ingeladen.

\begin{table}[H]
	\centering
	\begin{tabular}{|r|r|}
		\hline
		Aantal rijen & Tijd (s) \\
		\hline
		\hline
		1 000 & 0.388 \\
		\hline
		10 000 & 2.068 \\
		\hline
		100 000 & 23.635 \\
		\hline
		1 000 000 & 195.742 \\
		\hline
		10 000 000 & 2 150.821\\
		\hline
	\end{tabular}
	\caption{Importeren van data met cqlsh}
	\label{tab:cas_cqlsh}
\end{table}

Als men tabel \ref{tab:cas_cqlsh} bekijkt ziet men dat hier een lineair verband bestaat tussen het aantal rijen en de tijd die nodig is om alle rijen te importeren.
Dit leverde de verwachte resultaten op.

Een test met sstableloader werd niet uitgevoerd omdat daarvoor alle nodes online moeten zijn.
In een systeem waar alles ingezet wordt op hoge beschikbaarheid, is het dan ook niet aangeraden om een methode te gebruiken waar een import sowieso crasht als er een node offline gaat.

Het gebruik van cassandra-loader leverde veel problemen op.
Dit kwam deels door virtuele machines te gebruiken.
De cassandra-loader verwacht namelijk 8 GB werkgeheugen.
Op de virtuele machine was een dergelijke hoeveelheid werkgeheugen echter niet voorhanden.
Hierdoor moest het originele script lichtjes aangepast worden.
Na de aanpassing van het virtueel geheugen dat toegewezen wordt aan de Java virtuele machine, crashte het programma.

Doordat het inladen met cassandra-loader niet werkte kan er dus ook geen vergelijking tussen beide methodes gemaakt worden.
Er dient opgemerkt te worden dat beide manieren (cassandra-loader en importeren via cqlsh) in theorie niet zoveel van elkaar verschillen.
Het enige pluspunt dat cassandra-loader heeft, is dat deze tool het werk evenwichtig over alle online nodes gaat verdelen.